{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billbch/Imagen-Parse/blob/main/Image_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILqVnnpN7Noy",
        "outputId": "e1932eae-0adf-4413-ade4-0df048997f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIHP_PGN'...\n",
            "remote: Enumerating objects: 4398, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 4398 (delta 12), reused 18 (delta 4), pack-reused 4364\u001b[K\n",
            "Receiving objects: 100% (4398/4398), 851.18 KiB | 15.20 MiB/s, done.\n",
            "Resolving deltas: 100% (718/718), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Engineering-Course/CIHP_PGN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIHP_PGN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Ua6_As7af_",
        "outputId": "771b4157-b025-4705-94d6-9bac8ee984a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIHP_PGN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Mqpse5Gen4V4403wFEpv3w3JAsWw2uhk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvP7fjyg7c-9",
        "outputId": "aefc787f-cf92-41eb-ad99-6fcdef888fad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mqpse5Gen4V4403wFEpv3w3JAsWw2uhk\n",
            "To: /content/CIHP_PGN/CIHP_pgn.zip\n",
            "100% 1.23G/1.23G [00:25<00:00, 48.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip CIHP_pgn.zip -d /content/CIHP_PGN/checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okCrSab670IO",
        "outputId": "004a8fb9-ee6f-452b-93d4-9239760b1633"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CIHP_pgn.zip\n",
            "   creating: /content/CIHP_PGN/checkpoint/CIHP_pgn/\n",
            "  inflating: /content/CIHP_PGN/checkpoint/CIHP_pgn/checkpoint  \n",
            "  inflating: /content/CIHP_PGN/checkpoint/CIHP_pgn/model.ckpt-593292.data-00000-of-00001  \n",
            "  inflating: /content/CIHP_PGN/checkpoint/CIHP_pgn/model.ckpt-593292.index  \n",
            "  inflating: /content/CIHP_PGN/checkpoint/CIHP_pgn/model.ckpt-593292.meta  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de ejecutar, eliminar la linea de pip y numpy del archivo *requirement.txt*"
      ],
      "metadata": {
        "id": "t5JhvPTqLqpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirement.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XVT0HMh-fGo",
        "outputId": "f8c198e9-fc23-4a0f-a3f7-c7be7da0a62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting absl-py==0.15.0\n",
            "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: cached-property==1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 3)) (1.5.2)\n",
            "Collecting certifi==2021.10.8\n",
            "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 5)) (0.11.0)\n",
            "Collecting fonttools==4.29.1\n",
            "  Using cached fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 8)) (0.2.0)\n",
            "Collecting grpcio==1.42.0\n",
            "  Using cached grpcio-1.42.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "Collecting h5py==3.6.0\n",
            "  Using cached h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting importlib-metadata==4.8.2\n",
            "  Using cached importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting Keras-Applications==1.0.8\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 13)) (1.1.2)\n",
            "Collecting kiwisolver==1.3.2\n",
            "  Using cached kiwisolver-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting Markdown==3.3.4\n",
            "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Using cached matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Collecting mkl-fft==1.3.1\n",
            "  Using cached mkl_fft-1.3.1-16-cp37-cp37m-manylinux2014_x86_64.whl (241 kB)\n",
            "Collecting mkl-random==1.2.2\n",
            "  Using cached mkl_random-1.2.2-16-cp37-cp37m-manylinux2014_x86_64.whl (379 kB)\n",
            "Collecting mkl-service==2.4.0\n",
            "  Using cached mkl_service-2.4.0-11-cp37-cp37m-manylinux2014_x86_64.whl (63 kB)\n",
            "Collecting opencv-python==4.5.5.62\n",
            "  Using cached opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 21)) (3.3.0)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 22)) (21.3)\n",
            "Collecting Pillow==9.0.1\n",
            "  Using cached Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting pip==21.2.2\n",
            "  Using cached pip-21.2.2-py3-none-any.whl (1.6 MB)\n",
            "Collecting protobuf==3.19.1\n",
            "  Using cached protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting pyparsing==3.0.7\n",
            "  Using cached pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 27)) (2.8.2)\n",
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 28)) (1.7.3)\n",
            "Collecting setuptools==58.0.4\n",
            "  Using cached setuptools-58.0.4-py3-none-any.whl (816 kB)\n",
            "Collecting six==1.16.0\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting tensorboard==1.15.0\n",
            "  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "Collecting tensorflow==1.15.0\n",
            "  Using cached tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting termcolor==1.1.0\n",
            "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting typing-extensions==3.10.0.2\n",
            "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 36)) (0.5.1)\n",
            "Collecting Werkzeug==0.16.1\n",
            "  Using cached Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
            "Requirement already satisfied: wheel==0.37.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 38)) (0.37.1)\n",
            "Collecting wrapt==1.13.3\n",
            "  Using cached wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
            "Collecting zipp==3.7.0\n",
            "  Using cached zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.6.0->-r requirement.txt (line 10)) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft==1.3.1->-r requirement.txt (line 17)) (2019.0)\n",
            "Collecting dpcpp_cpp_rt\n",
            "  Downloading dpcpp_cpp_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 21.0 MB/s \n",
            "\u001b[?25hCollecting intel-cmplr-lic-rt==2022.2.0\n",
            "  Downloading intel_cmplr_lic_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (18 kB)\n",
            "Requirement already satisfied: intel-openmp==2022.2.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft==1.3.1->-r requirement.txt (line 17)) (2022.2.0)\n",
            "Collecting intel-cmplr-lib-rt==2022.2.0\n",
            "  Downloading intel_cmplr_lib_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (33.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.1 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting intel-opencl-rt==2022.2.0\n",
            "  Downloading intel_opencl_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (253.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 253.4 MB 52 kB/s \n",
            "\u001b[?25hCollecting tbb==2021.*\n",
            "  Downloading tbb-2021.7.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 55.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gast, termcolor\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=8a1c8ba6b35bba7f72d4dd7a7027ca9ae01fe4f71f9ab3e63b4f803d1cb862a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=6d9060732e21370886121f515c7b0585f36e8a038a18593ed15626b3c3e6da23\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "Successfully built gast termcolor\n",
            "Installing collected packages: zipp, typing-extensions, tbb, six, intel-cmplr-lic-rt, importlib-metadata, Werkzeug, setuptools, pyparsing, protobuf, Markdown, intel-opencl-rt, intel-cmplr-lib-rt, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, Pillow, kiwisolver, Keras-Applications, gast, fonttools, dpcpp-cpp-rt, tensorflow, pip, opencv-python, mkl-service, mkl-random, mkl-fft, matplotlib, certifi\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.9.0\n",
            "    Uninstalling zipp-3.9.0:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "wNEtO41oSRTp",
        "outputId": "d560ddaf-abc3-4d10-aa1a-85cf0004e01e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting pillow\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 27.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed pillow-9.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_pgn.py"
      ],
      "metadata": {
        "id": "1yDm8DN78lCb",
        "outputId": "fd38a2e8-8d77-4db2-b4e1-f55ea18a4b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"test_pgn.py\", line 16, in <module>\n",
            "    from utils import *\n",
            "  File \"/content/CIHP_PGN/utils/__init__.py\", line 1, in <module>\n",
            "    from .model_pgn import PGNModel\n",
            "  File \"/content/CIHP_PGN/utils/model_pgn.py\", line 6, in <module>\n",
            "    from kaffe.tensorflow import Network\n",
            "  File \"/content/CIHP_PGN/kaffe/__init__.py\", line 4, in <module>\n",
            "    from . import tensorflow\n",
            "  File \"/content/CIHP_PGN/kaffe/tensorflow/__init__.py\", line 1, in <module>\n",
            "    from .transformer import TensorFlowTransformer\n",
            "  File \"/content/CIHP_PGN/kaffe/tensorflow/transformer.py\", line 9, in <module>\n",
            "    from . import network\n",
            "  File \"/content/CIHP_PGN/kaffe/tensorflow/network.py\", line 3, in <module>\n",
            "    slim = tf.contrib.slim\n",
            "AttributeError: module 'tensorflow' has no attribute 'contrib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os,sys,shutil\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DATA_TYPE = ['png','PNG','jpg','JPG']\n",
        "def createDataset(path_img, name_dataset = 'CIHP'):\n",
        "    '''\n",
        "    USAGE = \"python %s /path_to_images name_of_dataset\" % sys.argv[0]\n",
        "    USAGE += \"\\nPlease put this code to the same path as test_pgn.py\"\n",
        "    if len(sys.argv)!=3 or '--help' in sys.argv or '-h' in sys.argv:\n",
        "        print(USAGE)\n",
        "        os._exit(0)\n",
        "    path_img = sys.argv[1]\n",
        "    name_dataset = sys.argv[2]\n",
        "    '''\n",
        "    path_dataset = os.path.join('.', 'datasets', name_dataset)\n",
        "    if os.path.isdir(path_dataset):\n",
        "        raise(Exception(\"the target dataset already exists, please delete that first.\"))\n",
        "        #shutil.rmtree(path_dataset)\n",
        "    os.makedirs(path_dataset)\n",
        "    path_edge = os.path.join(path_dataset, 'edges')\n",
        "    path_images = os.path.join(path_dataset, 'images')\n",
        "    path_list = os.path.join(path_dataset, 'list')\n",
        "    for p in [path_edge, path_images, path_list]:\n",
        "        os.makedirs(p)\n",
        "    files = [i for i in os.listdir(path_img) if i.split('.')[-1] in DATA_TYPE]\n",
        "    print(len(files))\n",
        "    #files = files[:]\n",
        "    for f in files:\n",
        "        im = Image.open(os.path.join(path_img, f))\n",
        "        #im = im.resize((im.size[0]*256//im.size[1],256), Image.LANCZOS) # if you run out of GPU memory\n",
        "        im1 = Image.new('L', im.size)\n",
        "        im.save(os.path.join(path_images, f))\n",
        "        im1.save(os.path.join(path_edge, '.'.join(f.split('.')[:-1])+'.png'))\n",
        "    with open(os.path.join(path_list, 'val.txt'), 'w') as flist:\n",
        "        for f in files:\n",
        "            flist.write('/images/%s /edges/%s\\n'%(f,'.'.join(f.split('.')[:-1])+'.png'))\n",
        "    with open(os.path.join(path_list, 'val_id.txt'), 'w') as flist:\n",
        "        for f in files:\n",
        "            flist.write('%s\\n'%'.'.join(f.split('.')[:-1]))\n",
        "\n",
        "createDataset('datasets/CIHP/images/', 'perron2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "oCDqdZeARVmx",
        "outputId": "5471760b-68f6-45ab-8403-fb34b546ac0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4b809de12a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mflist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s\\n'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mcreateDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/CIHP/images/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perron2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4b809de12a12>\u001b[0m in \u001b[0;36mcreateDataset\u001b[0;34m(path_img, name_dataset)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#files = files[:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m#im = im.resize((im.size[0]*256//im.size[1],256), Image.LANCZOS) # if you run out of GPU memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2896\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2897\u001b[0m                 \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'datasets/CIHP/images/0005008.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "print(PIL.__version__)"
      ],
      "metadata": {
        "id": "xRgKYMcMSD_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio as ii\n",
        "from PIL import Image\n",
        "nxb_img = Image.open('/content/CIHP_PGN/datasets/CIHP/images/front.jpg')      # This is your image.\n",
        " \n",
        "# Reshape their label image to our size \n",
        "label_img = Image.open('datasets/CIHP/labels/0005008.png')  # This is the label image from CIHP.\n",
        "nxb_label_img = label_img.resize(nxb_img.size, Image.NEAREST)\n",
        "nxb_label_img.save('datasets/CIHP/labels/front.png')\n",
        "\n",
        "# Reshape their edge image to our size \n",
        "edge_img  = Image.open('datasets/CIHP/edges/0005008.png')\n",
        "nxb_edge_img  = edge_img.resize(nxb_img.size, Image.NEAREST)\n",
        "nxb_edge_img.save('datasets/CIHP/edges/front.png')"
      ],
      "metadata": {
        "id": "b9_Tw2WsHz3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKXibhJ_F-qA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}